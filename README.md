# VVC
该工作为基于神经网络的帧内色度预测编码方法。
主要思路：为每个CU新增一种帧内色度预测模式，即通过网络模型预测CU色度值，该预测模式与原有的8种帧内色度预测模式通过RDO判断，选择出最优色度预测模式。
网络模型：针对YUV4:2：0格式的视频，用于CTU的色度预测(亮度大小128x128,色度大小64x64)。对于每个CTU，使用网络模型进行色度预测得到CTU色度预测值，
该CTU递归划分出的其他大小的编码块的色度预测值直接复制CTU相应位置的预测值。
嵌入到VVC编解码的流程：
编码端：每个CU额外编码一个标记位，若最优预测模式为基于神经网络的模式，编码标记位1，若最优预测模式为原有的8种帧内预测模式，编码标记位0，再编码具体的最优预测模式。
解码端：对于每个CU，先解码标记位，若为1，则最优预测模式为基于神经网络的模式，若为0，则接着解码得到最优的传统预测模式。
source：
在VTM8.2的基础上，实现了提出的基于神经网络的帧内色度预测编码方法。
EncoderApp和DecoderApp均有相应的代码修改。
1.使用宏定义ANNM标记是否开启提出的基于神经网络的方法。
2.使用宏定义SPLIT_SHOW标记是否在编码端开启输出重建视频块划分的可视化操作。（绿色块表示使用传统的帧内色度预测模式，红色块表示使用基于神经网络的预测模式。
  在函数在compressGOP（）函数中添加。）
3.使用神经网络模型作为最优色度预测模式的CU数量与所有CU数量的统计在解码端实现。在void CABACReader::intra_chroma_pred_mode()这个函数中，统计所有CU的数量与使用各种预测模式的CU数量。
